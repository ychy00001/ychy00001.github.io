<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>认识MyBatis</title>
    <url>/2021/06/%E8%AE%A4%E8%AF%86MyBatis/</url>
    <content><![CDATA[<p>MyBatis是java开发中常用的ORM框架，本文介绍MyBatis的入门使用。</p>
<h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>官网的简介写的比较好，建议大家直接去官网查看。<br><a href="https://mybatis.org/mybatis-3/zh/index.html">https://mybatis.org/mybatis-3/zh/index.html</a><br>简单点说MyBatis就是方便代码中操作数据库，避免了JDBS繁琐的设置及比编写。</p>
<span id="more"></span>
<blockquote>
<p>其他ORM框架</p>
</blockquote>
<ul>
<li>JDBC</li>
<li>JdbcTemplate</li>
<li>Hibernate </li>
</ul>
<h1 id="二、简单使用"><a href="#二、简单使用" class="headerlink" title="二、简单使用"></a>二、简单使用</h1><h4 id="1-创建maven项目-使用IDEA可以直接创建"><a href="#1-创建maven项目-使用IDEA可以直接创建" class="headerlink" title="1. 创建maven项目 使用IDEA可以直接创建"></a>1. 创建maven项目 使用IDEA可以直接创建</h4><h4 id="2-在resource目录创建mybatis-config-xml文件"><a href="#2-在resource目录创建mybatis-config-xml文件" class="headerlink" title="2. 在resource目录创建mybatis-config.xml文件"></a>2. 在resource目录创建mybatis-config.xml文件</h4><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE configuration
        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;
&lt;configuration&gt;
    &lt;environments default=&quot;development&quot;&gt;
        &lt;environment id=&quot;development&quot;&gt;
            &lt;transactionManager type=&quot;JDBC&quot;/&gt;
            &lt;dataSource type=&quot;POOLED&quot;&gt;
                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;
                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://$&#123;host&#125;/$&#123;database&#125;&quot;/&gt;
                &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt;
                &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt;
            &lt;/dataSource&gt;
        &lt;/environment&gt;
    &lt;/environments&gt;
    &lt;mappers&gt;
        &lt;mapper resource=&quot;mapper/UserMapper.xml&quot;/&gt;
    &lt;/mappers&gt;
&lt;/configuration&gt;
</code></pre>
<blockquote>
<p>注意 代码中${host}/${database} ${username}  ${password} 需要替换成自己对应的真实账号密码及链接路径</p>
</blockquote>
<h4 id="3-在resource目录创建mapper目录并创建UserMapper-xml文件"><a href="#3-在resource目录创建mapper目录并创建UserMapper-xml文件" class="headerlink" title="3. 在resource目录创建mapper目录并创建UserMapper.xml文件"></a>3. 在resource目录创建mapper目录并创建UserMapper.xml文件</h4><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper
        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.ychy.mybatis.mapper.UserMapper&quot;&gt;
    &lt;select id=&quot;selectUser&quot; resultType=&quot;com.ychy.mybatis.dao.User&quot;&gt;
        select * from User where id = #&#123;id&#125;
    &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
<blockquote>
<p>注意：namespace不是必须有这个包，mybatis使用namespace使用更长的限定名来将sql语句隔离开。<br>但是namespace我们都遵循这个规范就好，按照包名加类名来写，这样IDEA有插件可以方便跳转映射关系。见后面：使用正确描述每个语句的参数和返回值的接口UserMapper.java</p>
</blockquote>
<h4 id="4-单元测试"><a href="#4-单元测试" class="headerlink" title="4. 单元测试"></a>4. 单元测试</h4><pre><code class="java">public class MyBatisTest &#123;
    @Test
    public void testUserSelectOne() throws Exception&#123;
        String resource = &quot;mybatis-config.xml&quot;;
        InputStream inputStream = Resources.getResourceAsStream(resource);
        SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
        SqlSession sqlSession = sqlSessionFactory.openSession();
        // 第一种方式 直接调用
        User user = sqlSession.selectOne(&quot;com.ychy.mybatis.mapper.UserMapper.selectUser&quot;,1);
        System.out.println(user);
    &#125;
&#125;
</code></pre>
<blockquote>
<p>这里sqlSession调用selectOne方法中第一个参数就是UserMapper.xml中namespace+id凭借而成的。<br>第二个参数为要查询的ID</p>
</blockquote>
<h4 id="5-项目依赖"><a href="#5-项目依赖" class="headerlink" title="5.项目依赖"></a>5.项目依赖</h4><pre><code class="xml">  &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
            &lt;version&gt;3.5.3&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;8.0.19&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.12&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt;
            &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt;
            &lt;version&gt;$&#123;junit.jupiter.version&#125;&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.junit.platform&lt;/groupId&gt;
            &lt;artifactId&gt;junit-platform-launcher&lt;/artifactId&gt;
            &lt;version&gt;1.6.0&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;
</code></pre>
<h4 id="6-接口式编程（使用正确描述每个语句的参数和返回值的接口-gt-UserMapper-java）"><a href="#6-接口式编程（使用正确描述每个语句的参数和返回值的接口-gt-UserMapper-java）" class="headerlink" title="6. 接口式编程（使用正确描述每个语句的参数和返回值的接口-&gt;UserMapper.java）"></a>6. 接口式编程（使用正确描述每个语句的参数和返回值的接口-&gt;UserMapper.java）</h4><pre><code class="java">package com.ychy.mybatis.mapper;

import com.ychy.mybatis.dao.User;

public interface UserMapper &#123;
     User selectUser(int id);
&#125;
</code></pre>
<blockquote>
<p>为什么可以直接通过UserMapper接口就可以查询User呢？因为Mybatis底层使用了动态代理类。</p>
</blockquote>
<h5 id="单元测试可以更改如下"><a href="#单元测试可以更改如下" class="headerlink" title="单元测试可以更改如下"></a>单元测试可以更改如下</h5><pre><code class="java">public class MyBatisTest &#123;
    @Test
    public void testUserSelectOne() throws Exception&#123;
        String resource = &quot;mybatis-config.xml&quot;;
        InputStream inputStream = Resources.getResourceAsStream(resource);
        SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
        SqlSession sqlSession = sqlSessionFactory.openSession();
        // 第一种方式 直接调用
// User user = sqlSession.selectOne(&quot;com.ychy.mybatis.mapper.UserMapper.selectUser&quot;,1);
        // 第二种方式获取UserMapper 第二种方法有很多优势，首先它不依赖于字符串字面值，会更安全一点； 其次，如果你的 IDE 有代码补全功能，那么代码补全可以帮你快速选择已映射的 SQL 语句。
        UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
        User user = userMapper.selectUser(1);
        System.out.println(user);
    &#125;
&#125;
</code></pre>
<blockquote>
<p>这样不仅可以执行更清晰和类型安全的代码，而且还不用担心易错的字符串字面值以及强制类型转换</p>
</blockquote>
<h4 id="7-使用注解的方式访问"><a href="#7-使用注解的方式访问" class="headerlink" title="7. 使用注解的方式访问"></a>7. 使用注解的方式访问</h4><pre><code class="java">public interface UserMapper &#123;
     @Select(&quot;SELECT * FROM user WHERE id = #&#123;id&#125;&quot;)
     User selectUser(int id);
&#125;
</code></pre>
<h5 id="同时需要更改mybatis-config-xml"><a href="#同时需要更改mybatis-config-xml" class="headerlink" title="同时需要更改mybatis-config.xml"></a>同时需要更改mybatis-config.xml</h5><pre><code class="xml">    &lt;mappers&gt;
        &lt;!-- 使用xml方式 --&gt;
&lt;!-- &lt;mapper resource=&quot;mapper/UserMapper.xml&quot;/&gt; --&gt;
        &lt;!-- 使用注解方式方式 --&gt;
        &lt;mapper class=&quot;com.ychy.mybatis.mapper.UserMapper&quot;&gt;&lt;/mapper&gt;
    &lt;/mappers&gt;
</code></pre>
<blockquote>
<p>这样可以不用写UserMapper.xml文件，但是需要更改mybatis-config.xml中mappers的内容</p>
</blockquote>
<h4 id="8-注意：注解和xml形式不可同时使用，否则会报如下错误"><a href="#8-注意：注解和xml形式不可同时使用，否则会报如下错误" class="headerlink" title="8.注意：注解和xml形式不可同时使用，否则会报如下错误"></a>8.注意：注解和xml形式不可同时使用，否则会报如下错误</h4><pre><code>org.apache.ibatis.exceptions.PersistenceException: 
### Error building SqlSession.
### The error may exist in com/ychy/mybatis/mapper/UserMapper.java (best guess)
### Cause: org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: java.lang.IllegalArgumentException: Mapped Statements collection already contains value for com.ychy.mybatis.mapper.UserMapper.selectUser. please check mapper/UserMapper.xml and com/ychy/mybatis/mapper/UserMapper.java (best guess)
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>Linux exec命令使用</title>
    <url>/2021/06/Linux-exec%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>本文介绍exec的基本功能及使用方式。</p>
<h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>看到ngxin的docker-entrypoint.sh中写有exec相关命令不清楚为何如此使用，如下：</p>
<pre><code>#!/bin/sh
set -e
if [ -z &quot;$&#123;NGINX_ENTRYPOINT_QUIET_LOGS:-&#125;&quot; ]; then
    exec 3&gt;&amp;1
else
    exec 3&gt;/dev/null
fi
.....
</code></pre>
<span id="more"></span>
<p>在CentOS Linux release 7.9下查看man手册</p>
<pre><code>man exec
</code></pre>
<p>如何所示，该命令是bash中内嵌的命令：<br><img src="/2021/06/Linux-exec%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/1.png"></p>
<p>我们找到exec的描述信息：<br><img src="/2021/06/Linux-exec%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/2.png"></p>
<p>如果指定该命令，他会替换当前shell。并且不会创建新的进程。</p>
<h2 id="fork简介"><a href="#fork简介" class="headerlink" title="fork简介"></a>fork简介</h2><p>上面提到不会现在新的进程，这里不得不提一下linux的子进程概念。</p>
<p>fork命令是linux的系统调用，用来创建子进程。</p>
<blockquote>
<p>子进程概念：由另外一个进程（对应称之为父进程）所创建的进程。 子进程继承了父进程的大部分属性，例如文件描述符。</p>
</blockquote>
<p>我们在写shell时候会在开头定义：#!/bin/sh。这样在执行该xxx.sh文件时，系统会使用fork命令，重新开一个sub-shell来执行你的shell脚本。</p>
<h2 id="exec的执行"><a href="#exec的执行" class="headerlink" title="exec的执行"></a>exec的执行</h2><p>回到我们的exec命令，执行exec命令时，系统不会fork子进程，而是会用一个新的进程镜像来替换当前进程镜像。新的进程跟fork后的进程不一样，新的进程跟旧进程是有同样的pid（进程id）和同样的上下文环境。它将程序加载到当前进程空间，并在入口点运行exec需要执行的程序。</p>
<h2 id="总结：exec和fork的异同"><a href="#总结：exec和fork的异同" class="headerlink" title="总结：exec和fork的异同"></a>总结：exec和fork的异同</h2><p>fork: 创建新的子进程，父进程和子进程同时运行<br>exec: 创建进程镜像替换旧进程，没有父子进程一说。</p>
<h2 id="exec的应用"><a href="#exec的应用" class="headerlink" title="exec的应用"></a>exec的应用</h2><h3 id="exec-执行某个指令"><a href="#exec-执行某个指令" class="headerlink" title="exec 执行某个指令"></a>exec 执行某个指令</h3><p>exec执行某个命令会执行完并退出bash<br><img src="/2021/06/Linux-exec%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/3.png"></p>
<h3 id="exec-不执行命令"><a href="#exec-不执行命令" class="headerlink" title="exec 不执行命令"></a>exec 不执行命令</h3><p>exec未携带命令执行表示重定向bash中内容<br><img src="/2021/06/Linux-exec%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/4.png"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>回到我们开头解释我们nginx的docker-entrypoint.sh，如下代码：</p>
<pre><code># 如果没有设置（-z 如果字符串为空则返回true）NGINX_ENTRYPOINT_QUIET_LOGS标识
if [ -z &quot;$&#123;NGINX_ENTRYPOINT_QUIET_LOGS:-&#125;&quot; ]; then
    # 将标准错误输出（3：stderr）重定向至标准输出中（1：stdout，&amp; ：引用标识）
    exec 3&gt;&amp;1
else
    # 如果存在NGINX_ENTRYPOINT_QUIET_LOGS则将标准错误输出内容移除
    exec 3&gt;/dev/null
fi
</code></pre>
<blockquote>
<p>上述代码中3、1是shell文件描述符相关支持，参考后续博文介绍</p>
</blockquote>
<p>参考文献：<br><a href="https://www.geeksforgeeks.org/difference-fork-exec/">https://www.geeksforgeeks.org/difference-fork-exec/</a><br><a href="http://xstarcd.github.io/wiki/shell/exec_redirect.html">http://xstarcd.github.io/wiki/shell/exec_redirect.html</a></p>
]]></content>
  </entry>
  <entry>
    <title>RabbitMQ-Federation Plugin使用示例</title>
    <url>/2021/06/RabbitMQ-Federation-Plugin%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/</url>
    <content><![CDATA[<p>本文采用docker环境来做Federation Plugin配置的流程。</p>
<h1 id="基础环境准备"><a href="#基础环境准备" class="headerlink" title="基础环境准备"></a>基础环境准备</h1><h2 id="基础网络"><a href="#基础网络" class="headerlink" title="基础网络"></a>基础网络</h2><table>
<thead>
<tr>
<th>名称</th>
<th>ip</th>
<th>操作系统</th>
<th>mq版本</th>
</tr>
</thead>
<tbody><tr>
<td>rabbitmq</td>
<td>172.21.0.2</td>
<td>centos 8</td>
<td>3.x</td>
</tr>
<tr>
<td>rabbitmq-upstream</td>
<td>172.21.0.3</td>
<td>centos 8</td>
<td>3.x</td>
</tr>
</tbody></table>
<span id="more"></span>
<h2 id="自用docker-compose镜像"><a href="#自用docker-compose镜像" class="headerlink" title="自用docker-compose镜像"></a>自用docker-compose镜像</h2><pre><code>version: &#39;3&#39;

services:
  rabbitmq:
    # 管理界面 guest/guest
    image: rabbitmq:3-management
    container_name: rabbitmq
    hostname: my-rabbit
    volumes:
      - ./rabbitmq/conf/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
      - ./rabbitmq/data:/var/lib/rabbitmq/mnesia
    ports:
      - &#39;5672:5672&#39;
      - &#39;15672:15672&#39;
    networks:
      - rabbitmq-network

  rabbitmq-upstream:
    image: rabbitmq:3-management
    container_name: rabbitmq-upstream
    hostname: my-rabbit-upstream
    volumes:
      - ./rabbitmq/conf-upstream/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
      - ./rabbitmq/data-upstream:/var/lib/rabbitmq/mnesia
    ports:
      - &#39;5673:5672&#39;
      - &#39;15673:15672&#39;
    networks:
      - rabbitmq-network

networks:
  rabbitmq-network:
</code></pre>
<h2 id="运行docker-compose"><a href="#运行docker-compose" class="headerlink" title="运行docker-compose"></a>运行docker-compose</h2><pre><code>docker-compose up -d
</code></pre>
<h2 id="进入两个容器分别执行加载federation插件"><a href="#进入两个容器分别执行加载federation插件" class="headerlink" title="进入两个容器分别执行加载federation插件"></a>进入两个容器分别执行加载federation插件</h2><pre><code># 进入rabbitmq
docker-compose exec rabbitmq bash
rabbitmq-plugins enable rabbitmq_federation
rabbitmq-plugins enable rabbitmq_federation_management
# 进入rabbitmq-upstream
docker-compose exec rabbitmq-upstream bash
rabbitmq-plugins enable rabbitmq_federation
rabbitmq-plugins enable rabbitmq_federation_management
</code></pre>
<h2 id="查看容器ip"><a href="#查看容器ip" class="headerlink" title="查看容器ip"></a>查看容器ip</h2><pre><code>ifconfig
</code></pre>
<p>当前我的两个容器ip如下<br>|名称|ip|<br>|—|—|<br>|rabbitmq|172.21.0.3|<br>|rabbitmq-upstream|172.21.0.2|</p>
<h2 id="在rabbitmq容器设置upstream"><a href="#在rabbitmq容器设置upstream" class="headerlink" title="在rabbitmq容器设置upstream"></a>在rabbitmq容器设置upstream</h2><pre><code># 已在容器中不需要执行该命令
docker-compose exec rabbitmq bash
rabbitmqctl set_parameter federation-upstream my-upstream \
&#39;&#123;&quot;uri&quot;:&quot;amqp://guest:guest@172.21.0.2:5672&quot;,&quot;expires&quot;:3600000&#125;&#39;
</code></pre>
<p>设置好后ui界面会显示出对应的upstream。<br><img src="/2021/06/RabbitMQ-Federation-Plugin%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/1.png"></p>
<h2 id="在rabbitmq容器设置policy"><a href="#在rabbitmq容器设置policy" class="headerlink" title="在rabbitmq容器设置policy"></a>在rabbitmq容器设置policy</h2><pre><code># 已在容器中不需要执行该命令
docker-compose exec rabbitmq bash
rabbitmqctl set_policy --apply-to exchanges federate-me &quot;^amq\.&quot; &#39;&#123;&quot;federation-upstream-set&quot;:&quot;all&quot;&#125;&#39;
</code></pre>
<p>执行后可以查看federation对应UI界面会将本地的exchange与federate-me policy绑定<br><img src="/2021/06/RabbitMQ-Federation-Plugin%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/2.png"></p>
<p>同时federation-upstream容器对应UI界面会有对应的绑定关系展示<br><img src="/2021/06/RabbitMQ-Federation-Plugin%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/3.png"></p>
<h2 id="代码测试（python）"><a href="#代码测试（python）" class="headerlink" title="代码测试（python）"></a>代码测试（python）</h2><h3 id="生产者代码"><a href="#生产者代码" class="headerlink" title="生产者代码"></a>生产者代码</h3><p>生产者代码链接rabbitmq-upstream用于发送消息。</p>
<pre><code>import pika
import sys
import os

def main():
    # 创建链接
    connection = pika.BlockingConnection(pika.ConnectionParameters(&#39;localhost&#39;, &#39;5673&#39;))
    channel = connection.channel()
    # 声明一个本地upstream消息的队列
    channel.queue_declare(queue=&#39;receive-upstream&#39;)
    # 发送消息至exchange
    channel.basic_publish(exchange=&#39;amq.direct&#39;, routing_key=&#39;receive-upstream&#39;, body=&#39;Hello World!&#39;)
    print(&quot;[x] Sent &#39;Hello World!&#39;&quot;)
    connection.close()

if __name__ == &#39;__main__&#39;:
    try:
        main()
    except KeyboardInterrupt:
        print(&#39;Interrupted&#39;)
        try:
            sys.exit(0)
        except SystemExit:
            os._exit(0)
</code></pre>
<h3 id="消费者代码"><a href="#消费者代码" class="headerlink" title="消费者代码"></a>消费者代码</h3><p>生产者代码链接rabbitmq用于接收upstream的消息。</p>
<pre><code>import pika
import os
import sys
import time

def main():
    # 创建链接
    connection = pika.BlockingConnection(pika.ConnectionParameters(host=&#39;localhost&#39;, port=&#39;5672&#39;))
    channel = connection.channel()
    # 声明一个接受upstream消息的队列
    channel.queue_declare(queue=&#39;receive-upstream&#39;)
    # 绑定队列至接受upstream-exchange的一个exchange上
    channel.queue_bind(&#39;receive-upstream&#39;, &#39;amq.direct&#39;)

    # 接收消息，定义callback函数，接收消息回调该函数
    def callback(ch, method, properties, body):
        print(&quot;[x] Received %r &quot; % body)
        ch.basic_ack(delivery_tag=method.delivery_tag)

    channel.basic_consume(queue=&#39;receive-upstream&#39;, auto_ack=False, on_message_callback=callback)
    print(&#39; [*] Waiting for messages. To exit press CTRL+C&#39;)
    channel.start_consuming()

if __name__ == &#39;__main__&#39;:
    try:
        main()
    except KeyboardInterrupt:
        print(&#39;Interrupted&#39;)
        try:
            sys.exit(0)
        except SystemExit:
            os._exit(0)
</code></pre>
<h3 id="运行截图"><a href="#运行截图" class="headerlink" title="运行截图"></a>运行截图</h3><p><img src="/2021/06/RabbitMQ-Federation-Plugin%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/4.png"><br><img src="/2021/06/RabbitMQ-Federation-Plugin%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/5.png"></p>
]]></content>
  </entry>
  <entry>
    <title>RabbitMQ-Federation Plugin概述</title>
    <url>/2021/06/RabbitMQ-Federation-Plugin%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>最进在研究联邦学习框架FATE，FATE的部署方式有多种，其中有一种部署方式是基于spark来做分布式计算，并且使用Rabbitmq跨节点数据传输的（Federation Plug）。<br>文件简单介绍Rabbitmq的插件Federation Plugin的基本使用流程。</p>
<span id="more"></span>
<h1 id="简述FederationPlugin"><a href="#简述FederationPlugin" class="headerlink" title="简述FederationPlugin"></a>简述FederationPlugin</h1><p>FederationPlugin可以简单理解为不需要建立集群就可以在多个MQ服务的做消息传输。这样不建立集群就可以在不同的网络域下作数据传输。<br>如下图，可以基于队列消息传输，也可以基于exchange传输。<br><img src="/2021/06/RabbitMQ-Federation-Plugin%E6%A6%82%E8%BF%B0/1.png"></p>
<h1 id="基础使用流程"><a href="#基础使用流程" class="headerlink" title="基础使用流程"></a>基础使用流程</h1><h3 id="1-开启Federation插件"><a href="#1-开启Federation插件" class="headerlink" title="1. 开启Federation插件"></a>1. 开启Federation插件</h3><p>启用rabbitmq_federation插件，可选启用rabbitmq_federation_management插件，用于控制台界面操作。</p>
<pre><code>rabbitmq-plugins enable rabbitmq_federation
rabbitmq-plugins enable rabbitmq_federation_management
</code></pre>
<h3 id="2-设置upstream"><a href="#2-设置upstream" class="headerlink" title="2. 设置upstream"></a>2. 设置upstream</h3><p>upstream就是一个上游服务，假设现在有节点A和节点B两方，B想要消费A中的队列，则A就是B的upstream。<br><img src="/2021/06/RabbitMQ-Federation-Plugin%E6%A6%82%E8%BF%B0/2.png"></p>
<p>下述server-name就是上图172.xx.xx.xx所在的broker。<br>server-name格式具体请产品AMQP-URL：<a href="https://www.rabbitmq.com/uri-spec.html">https://www.rabbitmq.com/uri-spec.html</a><br>简单举例：<br>|URI|Username|Passowd|Host|Port|Vhost|<br>|—|—|—|—|—|—|<br>|amqp://user:pass@host:10000/vhost|”user”|”pass”|”host”|10000|”vhost”|<br>|amqp://user%61:%61pass@ho%61st:10000/v%2fhost|”usera”|”apass”|”hoast”|10000|”v/host”|<br>|amqp://host|||”host”|||</p>
<p>下述代码定义了一个名为my-upstream的federation-upstream，指定uri和expires，expires为消息的过期时间单位ms。</p>
<pre><code>rabbitmqctl set_parameter federation-upstream my-upstream \
&#39;&#123;&quot;uri&quot;:&quot;amqp://server-name&quot;,&quot;expires&quot;:3600000&#125;&#39;
</code></pre>
<blockquote>
<p>本文只展示了命令行设置方式，额外方式如：http、web UI等方式请参考官方文档<br><a href="https://www.rabbitmq.com/federation.html">https://www.rabbitmq.com/federation.html</a></p>
</blockquote>
<h3 id="3-设置policy"><a href="#3-设置policy" class="headerlink" title="3. 设置policy"></a>3. 设置policy</h3><p>policy可以理解为一个运行时配置，可以再mq运行时设置更改相关配置信息，具体参考官方文档：<a href="https://www.rabbitmq.com/parameters.html%E3%80%82">https://www.rabbitmq.com/parameters.html。</a><br>下述设置了一个policy，federate-me为自定义的名称，”^amq.“是正则表达式，用来匹配对应的exchanges，federation-upstream-set:”all”表示匹配所有的upstream。<br>概括下来就是，匹配所有amq.开头的exchange用来接收upstream消息</p>
<pre><code>rabbitmqctl set_policy --apply-to exchanges federate-me &quot;^amq\.&quot; &#39;&#123;&quot;federation-upstream-set&quot;:&quot;all&quot;&#125;&#39;
</code></pre>
<h3 id="4-写代码测试"><a href="#4-写代码测试" class="headerlink" title="4. 写代码测试"></a>4. 写代码测试</h3><p>上述正常配置后，假设有AB两个节点，B节点设置upstream为A，则A的所有消息都将被B接收。</p>
<blockquote>
<p>具体示例参考后续文章【RabbitMQ-Federation Plugin使用示例】</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>Spark on YARN最大化执行任务配置</title>
    <url>/2021/07/Spark-on-YARN%E6%9C%80%E5%A4%A7%E5%8C%96%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><p>本文简述spark调优历程，java服务端研发一枚，被要求搭建hadoop-spark环境运行机器学习。搭建完成后基本使用默认的配置文件执行任务，测试使用500MB的数据来运行逻辑回归，执行时间非常长，为了缩短任务运行时间，开始了无止尽的摸索参数配置。</p>
<span id="more"></span>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ul>
<li>本文采用三台4H8G机器为测试机器，配置只是为了让单个任务最大化使用系统资源。</li>
<li>本文配置文件内容仅供参考，需要根据实际机器资源和任务使用情况来自行设置</li>
<li>本文描述系统的CPU和内存资源时简写，示例：4H8G表示4个cpu核数，8GB的内存</li>
</ul>
<h1 id="yarn基础配置"><a href="#yarn基础配置" class="headerlink" title="yarn基础配置"></a>yarn基础配置</h1><p>spark是运行在yarn中的，所以先从yarn的配置文件下手，单台服务器为4H8G，预留1H1G给操作系统，剩下的全部配置给yarn使用。因为当前只需要一个任务最大化使用系统资源，所以最大可分配内存可以跟节点总内存一致。</p>
<h2 id="内存相关（yarn-site-xml）"><a href="#内存相关（yarn-site-xml）" class="headerlink" title="内存相关（yarn-site.xml）"></a>内存相关（yarn-site.xml）</h2><pre><code class="xml">   &lt;property&gt;  
        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
        &lt;value&gt;7168&lt;/value&gt;
        &lt;description&gt;当前节点可分配的总内存&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt; 
        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
        &lt;value&gt;1024&lt;/value&gt;
        &lt;description&gt;最小可分配容器内存&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
        &lt;value&gt;7168&lt;/value&gt;
        &lt;description&gt;最大可分配容器内存&lt;/description&gt;
    &lt;/property&gt;
</code></pre>
<h2 id="虚拟内存相关（yarn-site-xml）"><a href="#虚拟内存相关（yarn-site-xml）" class="headerlink" title="虚拟内存相关（yarn-site.xml）"></a>虚拟内存相关（yarn-site.xml）</h2><p>关闭虚拟内存的检查，在执行任务的时候如果分配虚拟内存超出了虚拟内存可用值则会杀掉容器。</p>
<pre><code class="xml">&lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
        &lt;description&gt;默认为true，当前关闭虚拟内存检查&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;
        &lt;value&gt;2.1&lt;/value&gt;
        &lt;description&gt;如果不关闭虚拟内存检查，并且任务运行需要占用大量内存时可以将改比率调高&lt;/description&gt;
&lt;/property&gt;
</code></pre>
<h2 id="cpu相关（yarn-site-xml）"><a href="#cpu相关（yarn-site-xml）" class="headerlink" title="cpu相关（yarn-site.xml）"></a>cpu相关（yarn-site.xml）</h2><p>cpu和基础设置跟内存一样，4H8G的服务器。预留一个CPU给操作系统以及任务调度运行。其他全部指定给yarn来使用。</p>
<pre><code class="xml">    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
        &lt;value&gt;7&lt;/value&gt;
        &lt;description&gt;当前节点可分配的总CPU&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.minimum-allocation-vcores&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
        &lt;description&gt;最小可分配容器CPU&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.maximum-allocation-vcores&lt;/name&gt;
        &lt;value&gt;7&lt;/value&gt;
        &lt;description&gt;最大可分配容器CPU&lt;/description&gt;
    &lt;/property&gt;
</code></pre>
<h2 id="其他资源相关配置（yarn-site-xml）"><a href="#其他资源相关配置（yarn-site-xml）" class="headerlink" title="其他资源相关配置（yarn-site.xml）"></a>其他资源相关配置（yarn-site.xml）</h2><p>下面配置用来设置调度器使用的资源比较计算器，默认资源计算器使用：org.apache.hadoop.yarn.util.resource.DefaultResourseCalculator，该资源计算器只根据内存来计算资源，在yarn的UI界面中也不会显示cpu分配的内容，采用DominantResourceCalculator可以多维度计算资源。</p>
<pre><code class="xml">&lt;property&gt;
        &lt;name&gt;yarn.scheduler.capacity.resource-calculator&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.yarn.util.resource.DominantResourceCalculator&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h2 id="调度器配置（capacity-scheduler-xml）"><a href="#调度器配置（capacity-scheduler-xml）" class="headerlink" title="调度器配置（capacity-scheduler.xml）"></a>调度器配置（capacity-scheduler.xml）</h2><p>该配置项较多，至列特殊几个配置供参考，之前碰到一个场景是我想在当前集群同时运行两个任务，每个任务占总资源的1/2，但是总是后面一个任务在padding中，申请不到资源。所以重点可以关注下面配置是否合理</p>
<pre><code>&lt;property&gt;xml
    &lt;name&gt;yarn.scheduler.capacity.maximum-am-resource-percent&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
    &lt;description&gt;
      运行任务可占用资源的最大百分比，如果该值不是100%则无法使用集群的全部资源并行执行任务
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.capacity.root.default.maximum-capacity&lt;/name&gt;
    &lt;value&gt;100&lt;/value&gt;
    &lt;description&gt;
       给root用户（我当前使用的用户）指定最大队列容量
    &lt;/description&gt;
  &lt;/property&gt;
</code></pre>
<h1 id="spark基础配置"><a href="#spark基础配置" class="headerlink" title="spark基础配置"></a>spark基础配置</h1><p>为了让运行的任务使用所有的资源，先计算所有可用资源有多少，当前yarn可分配的一共是3台服务器每台服务器3H7G内存，总计9H21G。</p>
<ul>
<li>假设分配4个容器执行任务，1个容器为ApplicationMaster用作spark资源调度。（–num-executors=4）</li>
<li>ApplicationMaster占用1H1G，剩余8G20G留给任务执行，每个容器可以使用2H5G。（  –executor-cores=2）</li>
<li>5G内容中需要有7%（默认值）的spark.executor.memoryOverhead，则5G*0.07=358.4MB，可以向上取整359MB，则5G-359MB=4761MB（–executor-memory=4761m）</li>
</ul>
<p>总结下来可以在执行任务时如下设置：</p>
<pre><code class="shell">./bin/spark-submit \
  --master yarn \
  --num-executors 4 \
  --executor-memory 4761m \
  --executor-cores 2 
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>Spark on YARN配置资源动态申请</title>
    <url>/2021/07/Spark-on-YARN%E9%85%8D%E7%BD%AE%E8%B5%84%E6%BA%90%E5%8A%A8%E6%80%81%E7%94%B3%E8%AF%B7/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>运行spark任务时通常任务会按照默认配置正常执行任务，这样当集群中还有空余资源时，这部分资源就会白白浪费，本文介绍如果为spark开启动态资源申请，当有空余资源时，spark任务会自动伸缩来达到更高效的资源利用。</p>
<blockquote>
<p>spark版本： 2.4.1            hadoop版本：2.8.5</p>
</blockquote>
<span id="more"></span>
<h1 id="spark相关配置（spark-defaults-conf）"><a href="#spark相关配置（spark-defaults-conf）" class="headerlink" title="spark相关配置（spark-defaults.conf）"></a>spark相关配置（spark-defaults.conf）</h1><h2 id="开启动态资源申请"><a href="#开启动态资源申请" class="headerlink" title="开启动态资源申请"></a>开启动态资源申请</h2><p>首先需要开启spark动态申请配置spark.dynamicAllocation.enabled，他还需要一些子配置需要设置如：minExecutors、maxExecutors等，大多数情况下为应用配置合适的执行器都需要设置这些子属性。设置这些属性的时候需要大量的试验来确保应用分配正确的执行器个数，过多的分配只会造成资源浪费。下面给出示例配置：</p>
<pre><code>spark.dynamicAllocation.enabled true
spark.dynamicAllocation.minExecutors 1
spark.dynamicAllocation.maxExecutors 10
spark.dynamicAllocation.schedulerBacklogTimeout 1s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5s
</code></pre>
<p>上述配置中额外设置了schedulerBacklogTimeout和sustainedSchedulerBacklogTimeout</p>
<ul>
<li>schedulerBacklogTimeout  表示：如果有处于Pending中的Task等待了一段时间(默认1秒)，则增加executor</li>
<li>sustainedSchedulerBacklogTimeout 表示：在随后每隔N秒(默认1秒)，再检测Pending Task，如果仍然存在，则继续增加executor。</li>
</ul>
<h2 id="开启shuffle服务器"><a href="#开启shuffle服务器" class="headerlink" title="开启shuffle服务器"></a>开启shuffle服务器</h2><p>开启了spark.dynamicAllocation.enabled后还需要启动一个外部shuffle服务，供YARN使用。</p>
<pre><code>spark.shuffle.service.enabled true
spark.shuffle.service.port 7337
</code></pre>
<h1 id="yarn相关配置（yarn-siete-xml）"><a href="#yarn相关配置（yarn-siete-xml）" class="headerlink" title="yarn相关配置（yarn-siete.xml）"></a>yarn相关配置（yarn-siete.xml）</h1><h2 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h2><pre><code class="xml">&lt;property&gt;
　　&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
　　&lt;value&gt;mapreduce_shuffle,spark_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
　　&lt;name&gt;yarn.nodemanager.aux-services.spark_shuffle.class&lt;/name&gt;
　　&lt;value&gt;org.apache.spark.network.yarn.YarnShuffleService&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
　　&lt;name&gt;spark.shuffle.service.port&lt;/name&gt;
　　&lt;value&gt;7337&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h2 id="额外操作"><a href="#额外操作" class="headerlink" title="额外操作"></a>额外操作</h2><p>为了让yarn支持spark的动态资源申请，还需要添加spark-yarn-shuffle的jar包：spark-<version>-yarn-shuffle.jar，本文使用spark-2.4.1版本，对应jar包位置在SPARK_HOME/yarn/spark-2.4.1-yarn-shuffle.jar。将该jar包放置HADOOP_HOME/share/hadoop/yarn/lib/目录下。</p>
]]></content>
  </entry>
  <entry>
    <title>OpenResty反向代理增加DNS解析支持</title>
    <url>/2021/08/OpenResty%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%A2%9E%E5%8A%A0DNS%E8%A7%A3%E6%9E%90%E6%94%AF%E6%8C%81/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>当前工作中使用了开源的联邦学习框架FATE，其中“on spark”架构中使用到了OpenResty来做网关，docker部署服务时服务间的通讯直接使用docker-hostname来访问的，但是OpenResty中调用set_current_peer()无法直接请求hostname。代码片段如下</p>
<span id="more"></span>
<pre><code>local ngx = ngx
local ngx_balancer = require &quot;ngx.balancer&quot;

local function balance()
    local dest_cluster = ngx.ctx.dest_cluster
    -- 当前代理服务请求目标服务时只支持ip地址请求，dest_cluster实际内容为：ip+端口号
    local ok, err = ngx_balancer.set_current_peer(dest_cluster)
    if not ok then
        return ngx.ERROR
    end
end

balance()
</code></pre>
<h1 id="简介Nginx的resolver"><a href="#简介Nginx的resolver" class="headerlink" title="简介Nginx的resolver"></a>简介Nginx的resolver</h1><p>Nginx本身提供了resolver指令来解析hostname。</p>
<pre><code>Syntax:    resolver address ... [valid=time] [ipv6=on|off];
Default:     —
Context:    http, server, location
</code></pre>
<p>示例：</p>
<pre><code>resolver 8.8.8.8 114.114.114.114 valid=3600s;
</code></pre>
<h1 id="Lua-DNS解析支持"><a href="#Lua-DNS解析支持" class="headerlink" title="Lua-DNS解析支持"></a>Lua-DNS解析支持</h1><p>代码如下，读取/etc/resolv.conf文件中DNS地址，缓存该地址提高运行效率，通过lua-resty-dns库提供的方法解析域名获取实际IP地址。（代码中require “resolver”是用的lua-resty-dns库自定义的名称）</p>
<blockquote>
<p>获得lua-resty-dns请从git下载：<a href="https://github.com/openresty/lua-resty-dns">https://github.com/openresty/lua-resty-dns</a></p>
</blockquote>
<p>代码文件：host_resolver.lua</p>
<pre><code>local _M = &#123;
  _VERSION = &#39;0.1&#39;
&#125;

local resolver = require &quot;resolver&quot;
local pcall = pcall
local io_open = io.open
local ngx_re_gmatch = ngx.re.gmatch
local require = require
local ngx_re_find = ngx.re.find
local lrucache = require &quot;resty.lrucache&quot;
local cache_storage = lrucache.new(200)
local ok, new_tab = pcall(require, &quot;table.new&quot;)

if not ok then
    new_tab = function (narr, nrec) return &#123;&#125; end
end

local _dns_servers = new_tab(5, 0)

local _read_file_data = function(path)
    local f, err = io_open(path, &#39;r&#39;)

    if not f or err then
        return nil, err
    end

    local data = f:read(&#39;*all&#39;)
    f:close()
    return data, nil
end

local _read_dns_servers_from_resolv_file = function()
    local text = _read_file_data(&#39;/etc/resolv.conf&#39;)

    local captures, it, err
    it, err = ngx_re_gmatch(text, [[^nameserver\s+(\d+?\.\d+?\.\d+?\.\d+$)]], &quot;jomi&quot;)

    for captures, err in it do
        if not err then
            _dns_servers[#_dns_servers + 1] = captures[1]
        end
    end
end

local _is_addr = function(hostname)
    return ngx_re_find(hostname, [[\d+?\.\d+?\.\d+?\.\d+$]], &quot;jo&quot;)
end

function _M.resolve(hostname)
  if _is_addr(hostname) then
      return hostname, hostname
  end

  local addr = cache_storage:get(hostname)

  if addr then
      return addr, hostname
  end

  local r, err = resolver:new(&#123;
      nameservers = _dns_servers,
      retrans = 5,  -- 5 retransmissions on receive timeout
      timeout = 2000,  -- 2 sec
  &#125;)

  if not r then
      return nil, hostname
  end

  local answers, err = r:query(hostname, &#123;qtype = r.TYPE_A&#125;)

  if not answers or answers.errcode then
      return nil, hostname
  end

  for i, ans in ipairs(answers) do
      if ans.address then
          cache_storage:set(hostname, ans.address, 300)
          return ans.address, hostname
      end
  end

  return nil, hostname
end

_read_dns_servers_from_resolv_file()

return _M
</code></pre>
<h1 id="解析host"><a href="#解析host" class="headerlink" title="解析host"></a>解析host</h1><p>这样在读取到hostname的时候可以将其转换成ip地址发起调用。</p>
<pre><code>-- 读取上一步编写的配置文件
local host_resolver = require &quot;host_resolver&quot;
-- 解析服务
local server_ip = host_resolver.resolve(&quot;www.baidu.com&quot;)
</code></pre>
<blockquote>
<p>上述代码结合需要结合实际业务放在合适的位置，本文开头调用服务代码没有修改，是在它之前对hostname做了处理保证发起调用是使用ip调用。</p>
</blockquote>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://moonbingbing.gitbooks.io/openresty-best-practices/content/dns/use_dynamic_dns.html">https://moonbingbing.gitbooks.io/openresty-best-practices/content/dns/use_dynamic_dns.html</a><br><a href="https://moonbingbing.gitbooks.io/openresty-best-practices/content/ngx_lua/resolve_the_domain_name.html">https://moonbingbing.gitbooks.io/openresty-best-practices/content/ngx_lua/resolve_the_domain_name.html</a></p>
]]></content>
  </entry>
</search>
